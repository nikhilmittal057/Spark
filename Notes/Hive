Hive Notes
---------------------------

1.hive --service hiveserver2 &
2.hive --service metastore

set hive.cli.print.header=true ---> To show table headers

A.HOW TO CREATE A PARTITIONED HIVE TABLE AND HOW TO LOAD LOCAL(LINUX) FILE TO THAT HIVE TABLE:-
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

1.hive>create table emp(name string, age int) partitioned by (dob string) row format delimited fields terminated by '\t';
2.hive> load data local inpath '/home/nikhil/bigdata/jobs/emp' into table emp partition (dob='01-01-01');

B.OVEREWRITE:-
-------------------------

STEP:- 1) nikhil@myubuntu:~/bigdata/jobs$ hadoop fs -mkdir /user/hive/warehouse/apache.db/emp/dob=01-01-1991- create dob=01-01-1991 directory.
STEP:- 2) nikhil@myubuntu:~/bigdata/jobs$ hadoop fs -put emp /user/hive/warehouse/apache.db/emp/dob=01-01-1991--> loading emp file.
STEP:- 3) hive> load data local inpath '/home/nikhil/bigdata/jobs/emp' overwrite into table emp partition (dob='01-01-1991');---> overwrite in hive.


-use  

create table stocks (market varchar(20), stock varchar(20), sdate date, open double, high double, low double, closed double, volume bigint);

LOAD DATA LOCAL INFILE '/home/nikhil/bigdata/jobs/stocks' INTO TABLE stocks;

    SELECT DISTINCT stock FROM stocks ORDER BY stock;

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

HIVE INSERT:-  People1 (Normal table) and People (Bucketed and transactional table)  :- In Hive Update and Delete operation only allowed on transactional tables.
----------------------------------------------------------------------------------------------------------------------------------

hive> create table people1 (sno int, name string, age int);
hive> insert into table people1(sno, name, age) values(100, 'Hari', 30);
hive> delete from people1 where sno ='100';
FAILED: SemanticException [Error 10297]: Attempt to do update or delete on table apache.people1 that does not use an AcidOutputFormat or is not bucketed
FAILED: SemanticException [Error 10294]: Attempt to do update or delete using transaction manager that does not support these operations.

-->Then will create a bucketed and Transactional table to perform INSERT, UPDATE and DELETE.
-----------------------------------------

hive> create table people(sno int, name string, age int) STORED AS ORCfile TBLPROPERTIES ('transactional'='true');
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:The table must be bucketed and stored using an ACID compliant format (such as ORC))


hive> create table people(sno int, name string, age int) clustered by (name) sorted by (age) into 2 buckets STORED AS ORCfile TBLPROPERTIES ('transactional'='true');
hive> insert into table people select * from people1;
FAILED: SemanticException [Error 10298]: ACID insert, update, delete not supported on tables that are sorted, table people.


hive> create table people(sno int, name string, age int) clustered by (name) into 2 buckets STORED AS ORCfile TBLPROPERTIES ('transactional'='true');
hive> insert into table people select * from people1;
FAILED: SemanticException [Error 10265]: This command is not allowed on an ACID table apache.people with a non-ACID transaction manager. Failed command: insert into table people select * from people1

hive> SET hive.support.concurrency=true; 
hive> SET hive.enforce.bucketing=true; 
hive> SET hive.exec.dynamic.partition.mode=nonstrict; 
hive> SET hive.txn.manager=org.apache.hadoop.hive.ql.lockmgr.DbTxnManager; 
hive> SET hive.compactor.initiator.on=true; 
hive> SET hive.compactor.worker.threads=1; 
hive> SET hive.optimize.sort.dynamic.partition=false;

hive>insert into table people(sno, name, age) values(100, 'Hari', 30);
 
                                                  OR

hive> insert into table people select * from people1;

hive>delete from people where sno ='100'; - working
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Most of the answers here have suggested to either use hiveconf or hivevar namespace to store the variable. And all those answers are right. However, there is one more namespace.

There are total three namespaces available for holding variables.

  1.  hiveconf - hive started with this, all the hive configuration is stored as part of this conf. Initially, variable substitution was not part of hive and when it got introduced, all the user-defined variables were stored as part of this as well. Which is definitely not a good idea. So two more namespaces were created.
  2.  hivevar: To store user variables
  3.  system: To store system variables.

And so if you are storing a variable as part of a query (i.e. date or product_number) you should use hivevar namespace and not hiveconf namespace.

And this is how it works.

hiveconf is still the default namespace, so if you don't provide any namespace it will store your variable in hiveconf namespace.

However, when it comes to referring a variable, it's not true. By default it refers to hivevar namespace. Confusing, right? It can become clearer with the following example.

If you do not provide namespace as mentioned below, variable var will be stored in hiveconf namespace.

set var="default_namespace";

So, to access this you need to specify hiveconf namespace

select ${hiveconf:var};

And if you do not provide namespace it will give you an error as mentioned below, reason being that by default if you try to access a variable it checks in hivevar namespace only. And in hivevar there is no variable named var

select ${var}; 

We have explicitly provided hivevar namespace

set hivevar:var="hivevar_namespace";

as we are providing the namespace this will work.

select ${hivevar:var}; 

And as default, workspace used during referring a variable is hivevar, the following will work too.

select ${var};
























































